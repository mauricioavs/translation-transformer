{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa600014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "torch.Size([2, 2])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.device)  # En qué dispositivo está (CPU o GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ceb1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10., grad_fn=<SumBackward0>)\n",
      "tensor([2., 2.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = a * 2\n",
    "c = b.sum()\n",
    "print(c)\n",
    "c.backward()  # Calcula gradientes\n",
    "print(a.grad)  # da [2, 2] porque d(a*2)/da = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29d822",
   "metadata": {},
   "source": [
    "nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42865a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7abff4d24390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc534b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weight matrix shape: torch.Size([10, 4])\n",
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
      "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
      "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a simple embedding layer\n",
    "\n",
    "vocab_size = 10        # number of token IDs: 0..9\n",
    "embedding_dim = 4      # size of the embedding vector\n",
    "\n",
    "emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "print(\"Embedding weight matrix shape:\", emb.weight.shape)\n",
    "print(emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cccf7ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: 3\n",
      "Output vector shape: torch.Size([4])\n",
      "tensor([ 0.1198,  1.2377,  1.1168, -0.2473], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Pass a single token ID\n",
    "\n",
    "token_id = torch.tensor(3)\n",
    "vec = emb(token_id)\n",
    "\n",
    "print(\"Token ID:\", token_id.item())\n",
    "print(\"Output vector shape:\", vec.shape)\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe648c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: tensor([1, 4, 3, 9])\n",
      "Output shape: torch.Size([4, 4])\n",
      "tensor([[ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Pass a sequence of token IDs (1D tensor)\n",
    "\n",
    "seq = torch.tensor([1, 4, 3, 9])\n",
    "vecs = emb(seq)\n",
    "\n",
    "print(\"Input sequence:\", seq)\n",
    "print(\"Output shape:\", vecs.shape)\n",
    "print(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd931bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of token IDs:\n",
      " tensor([[1, 4, 3, 9, 0],\n",
      "        [2, 2, 5, 0, 0]])\n",
      "Output shape: torch.Size([2, 5, 4])\n",
      "tensor([[[ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "         [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "         [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "         [-0.5181, -0.3067, -1.5810,  1.7066],\n",
      "         [-1.1258, -1.1524, -0.2506, -0.4339]],\n",
      "\n",
      "        [[ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "         [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "         [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "         [-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "         [-1.1258, -1.1524, -0.2506, -0.4339]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Pass a batch of sequences (2D tensor)\n",
    "\n",
    "batch = torch.tensor([\n",
    "    [1, 4, 3, 9, 0],\n",
    "    [2, 2, 5, 0, 0],\n",
    "])\n",
    "\n",
    "vecs_batch = emb(batch)\n",
    "\n",
    "print(\"Batch of token IDs:\\n\", batch)\n",
    "print(\"Output shape:\", vecs_batch.shape)  # (batch_size, seq_len, embedding_dim)\n",
    "print(vecs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b27e641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5943,  1.5419,  0.5073, -0.5910],\n",
      "        [-1.3253,  0.1886, -0.0691, -0.4949],\n",
      "        [-1.4959, -0.1938,  0.4455,  1.3253],\n",
      "        [ 1.5091,  2.0820,  1.7067,  2.3804],\n",
      "        [-1.1256, -0.3170, -1.0925, -0.0852],\n",
      "        [ 1.6459, -1.3602,  0.3446,  0.5199],\n",
      "        [-2.6133, -1.6965, -0.2282,  0.2800],\n",
      "        [ 0.2469,  0.0769,  0.3380,  0.4544],\n",
      "        [ 0.4569, -0.8654,  0.7813, -0.9268]], requires_grad=True)\n",
      "\n",
      "Embedding for padding index (should be zeros):\n",
      "tensor([0., 0., 0., 0.], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding with a padding index\n",
    "\n",
    "pad_id = 0\n",
    "\n",
    "emb_pad = nn.Embedding(\n",
    "    num_embeddings=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    padding_idx=pad_id\n",
    ")\n",
    "\n",
    "print(\"Embedding weights:\")\n",
    "print(emb_pad.weight)\n",
    "\n",
    "print(\"\\nEmbedding for padding index (should be zeros):\")\n",
    "print(emb_pad.weight[pad_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27f20140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch with padding:\n",
      " tensor([[1, 2, 3, 0, 0],\n",
      "        [4, 5, 0, 0, 0]])\n",
      "Embeddings (notice the 0-vectors for padding positions):\n",
      "tensor([[[ 0.5943,  1.5419,  0.5073, -0.5910],\n",
      "         [-1.3253,  0.1886, -0.0691, -0.4949],\n",
      "         [-1.4959, -0.1938,  0.4455,  1.3253],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.5091,  2.0820,  1.7067,  2.3804],\n",
      "         [-1.1256, -0.3170, -1.0925, -0.0852],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "Embedding values for padding positions (all zeros):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Pass sequences containing padding (ID 0)\n",
    "\n",
    "batch_with_pad = torch.tensor([\n",
    "    [1, 2, 3, 0, 0],\n",
    "    [4, 5, 0, 0, 0],\n",
    "])\n",
    "\n",
    "vecs_with_pad = emb_pad(batch_with_pad)\n",
    "\n",
    "print(\"Batch with padding:\\n\", batch_with_pad)\n",
    "print(\"Embeddings (notice the 0-vectors for padding positions):\")\n",
    "print(vecs_with_pad)\n",
    "\n",
    "print(\"\\nEmbedding values for padding positions (all zeros):\")\n",
    "print(vecs_with_pad[batch_with_pad == pad_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21a6e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x:\n",
      "tensor([[3., 5., 2., 7., 4., 1.]])\n",
      "\n",
      "Dropout output y:\n",
      "tensor([[0., 0., 4., 0., 0., 0.]])\n",
      "\n",
      "Dropout mask (1 = kept unit, 0 = dropped):\n",
      "tensor([[0., 0., 1., 0., 0., 0.]])\n",
      "\n",
      "Applied scale factor: 2.0\n",
      "\n",
      "Reconstructed output (mask * x * scale):\n",
      "tensor([[0., 0., 2., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Cell: Visualizing how dropout works on a single vector\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)   # for reproducibility\n",
    "\n",
    "# Create a dropout layer with p = 0.5\n",
    "drop = nn.Dropout(p=0.5)\n",
    "\n",
    "# A simple vector input\n",
    "x = torch.tensor([[3.0, 5.0, 2.0, 7.0, 4.0, 1.0]])\n",
    "\n",
    "# Apply dropout\n",
    "y = drop(x)\n",
    "\n",
    "# Manually build the dropout mask (for understanding)\n",
    "# PyTorch internally draws random Bernoulli values (0 or 1)\n",
    "mask = (y != 0).float() * (1 - drop.p)\n",
    "\n",
    "# The inverted-dropout scaling factor (1 / (1 - p))\n",
    "scale = 1.0 / (1.0 - drop.p)\n",
    "\n",
    "# Print everything\n",
    "print(\"Input x:\")\n",
    "print(x)\n",
    "\n",
    "print(\"\\nDropout output y:\")\n",
    "print(y)\n",
    "\n",
    "print(\"\\nDropout mask (1 = kept unit, 0 = dropped):\")\n",
    "print((y != 0).float())\n",
    "\n",
    "print(\"\\nApplied scale factor:\", scale)\n",
    "\n",
    "print(\"\\nReconstructed output (mask * x * scale):\")\n",
    "print(mask * x * scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
